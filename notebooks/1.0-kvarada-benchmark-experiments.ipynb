{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vkolhatk/anaconda3/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys \n",
    "sys.path.append(os.environ['HOME'] + '/src/models/')\n",
    "from deeplearning_models import DLTextClassifier\n",
    "from feature_based_models import FBConstructivenessClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# classifiers / models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# other\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_scores(model, X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    print(\"Training accuracy:   %.2f\" % (model.score(X_train, y_train)))\n",
    "    print(\"Validation accuracy: %.2f\" % (model.score(X_valid, y_valid)))\n",
    "    predictions = list(model.predict(X_train))\n",
    "    true_labels = y_train.tolist()\n",
    "    print('TRAIN CLASSIFICATION REPORT\\n\\n', classification_report(true_labels, predictions))\n",
    "    \n",
    "    predictions = list(model.predict(X_valid))\n",
    "    true_labels = y_valid.tolist()\n",
    "    print('VALIDATION CLASSIFICATION REPORT\\n\\n', classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "C3_train_df = pd.read_csv(os.environ['C3_FEATS_TRAIN'])\n",
    "C3_train_df['pp_comment_text'] = C3_train_df['pp_comment_text'].astype(str)\n",
    "\n",
    "C3_test_df = pd.read_csv(os.environ['C3_FEATS_TEST'])\n",
    "C3_test_df['pp_comment_text'] = C3_test_df['pp_comment_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_C3_train = C3_train_df.constructive_binary     \n",
    "X_C3_train = C3_train_df.drop(['constructive_binary'], axis = 1)\n",
    "\n",
    "#SOCC_a_df = pd.read_csv('/home/vkolhatk/dev/constructiveness//data/external/SOCC//annotated/constructiveness/SFU_constructiveness_toxicity_corpus_preprocessed.csv')    \n",
    "\n",
    "#X_SOCC_a = SOCC_a_df['pp_comment_text'].astype(str)\n",
    "#y_SOCC_a = SOCC_a_df['is_constructive']\n",
    "\n",
    "y_C3_test = C3_test_df.constructive_binary     \n",
    "X_C3_test = C3_test_df.drop(['constructive_binary'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  DummyClassifier(constant=None, random_state=None, strategy='stratified')\n",
      "Feature set:  ['ngram_feats', 'tfidf_feats', 'length_feats', 'argumentation_feats', 'text_quality_feats', 'named_entity_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Model trained and pickled in file:  /home/vkolhatk/dev/constructiveness/models/saved_model.h5\n",
      "Training accuracy:   0.51\n",
      "Validation accuracy: 0.49\n",
      "TRAIN CLASSIFICATION REPORT\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.47      0.47      0.47      4391\n",
      "        1.0       0.56      0.56      0.56      5209\n",
      "\n",
      "avg / total       0.52      0.52      0.52      9600\n",
      "\n",
      "VALIDATION CLASSIFICATION REPORT\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.45      0.44      0.45      1093\n",
      "        1.0       0.54      0.55      0.54      1307\n",
      "\n",
      "avg / total       0.50      0.50      0.50      2400\n",
      "\n",
      "sklearn micro-F1-Score: 0.5004166666666666\n"
     ]
    }
   ],
   "source": [
    "feature_set = ['text_features']\n",
    "\n",
    "classifier = FBConstructivenessClassifier(X_C3_train, y_C3_train, X_C3_test, y_C3_test)\n",
    "pipeline = classifier.train_pipeline(classifier = DummyClassifier())#'ngram_feats', 'tfidf_feats', 'pos_feats'])\n",
    "\n",
    "classifier.show_scores(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on C3 train and test on SOCC_a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test corpus \n",
    "SOCC_a_df = pd.read_csv(os.environ['SOCC_ANNOTATED_FEATS_PREPROCESSED'])\n",
    "SOCC_a_df['pp_comment_text'] = SOCC_a_df['pp_comment_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_SOCC_a = SOCC_a_df['constructive']\n",
    "X_SOCC_a = SOCC_a_df.drop(['constructive'], axis = 1)\n",
    "feature_set = ['length_feats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM :\n",
      "Classifier:  SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "Feature set:  ['ngram_feats', 'tfidf_feats', 'length_feats', 'argumentation_feats', 'text_quality_feats', 'named_entity_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "COMMENTS COL:  pp_comment_text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vkolhatk/anaconda3/envs/py35/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and pickled in file:  /home/vkolhatk/dev/constructiveness/models/saved_model.h5\n",
      "Training accuracy:   1.00\n",
      "Validation accuracy: 0.87\n",
      "TRAIN CLASSIFICATION REPORT\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      4391\n",
      "        1.0       1.00      1.00      1.00      5209\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9600\n",
      "\n",
      "VALIDATION CLASSIFICATION REPORT\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.92      0.87       484\n",
      "        1.0       0.92      0.83      0.87       551\n",
      "\n",
      "avg / total       0.88      0.87      0.87      1035\n",
      "\n",
      "sklearn micro-F1-Score: 0.8714975845410629\n",
      "Elapsed time: 41.5 s\n",
      "\n",
      "random forest :\n",
      "Classifier:  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Feature set:  ['ngram_feats', 'tfidf_feats', 'length_feats', 'argumentation_feats', 'text_quality_feats', 'named_entity_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Model trained and pickled in file:  /home/vkolhatk/dev/constructiveness/models/saved_model.h5\n",
      "Training accuracy:   0.99\n",
      "Validation accuracy: 0.79\n",
      "TRAIN CLASSIFICATION REPORT\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      4391\n",
      "        1.0       1.00      0.99      1.00      5209\n",
      "\n",
      "avg / total       0.99      0.99      0.99      9600\n",
      "\n",
      "VALIDATION CLASSIFICATION REPORT\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      0.95      0.81       484\n",
      "        1.0       0.93      0.64      0.76       551\n",
      "\n",
      "avg / total       0.82      0.79      0.78      1035\n",
      "\n",
      "sklearn micro-F1-Score: 0.7855072463768116\n",
      "Elapsed time: 50.1 s\n",
      "\n",
      "xgboost :\n",
      "Classifier:  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "Feature set:  ['ngram_feats', 'tfidf_feats', 'length_feats', 'argumentation_feats', 'text_quality_feats', 'named_entity_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Model trained and pickled in file:  /home/vkolhatk/dev/constructiveness/models/saved_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vkolhatk/anaconda3/envs/py35/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:   0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vkolhatk/anaconda3/envs/py35/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vkolhatk/anaconda3/envs/py35/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN CLASSIFICATION REPORT\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.95      0.95      4391\n",
      "        1.0       0.96      0.95      0.96      5209\n",
      "\n",
      "avg / total       0.95      0.95      0.95      9600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vkolhatk/anaconda3/envs/py35/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION CLASSIFICATION REPORT\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.93      0.88       484\n",
      "        1.0       0.93      0.83      0.88       551\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1035\n",
      "\n",
      "sklearn micro-F1-Score: 0.8772946859903382\n",
      "Elapsed time: 100.8 s\n",
      "\n",
      "logistic regression :\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Feature set:  ['ngram_feats', 'tfidf_feats', 'length_feats', 'argumentation_feats', 'text_quality_feats', 'named_entity_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Model trained and pickled in file:  /home/vkolhatk/dev/constructiveness/models/saved_model.h5\n",
      "Training accuracy:   1.00\n",
      "Validation accuracy: 0.87\n",
      "TRAIN CLASSIFICATION REPORT\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      4391\n",
      "        1.0       1.00      1.00      1.00      5209\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9600\n",
      "\n",
      "VALIDATION CLASSIFICATION REPORT\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.92      0.87       484\n",
      "        1.0       0.92      0.82      0.87       551\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1035\n",
      "\n",
      "sklearn micro-F1-Score: 0.8685990338164251\n",
      "Elapsed time: 45.5 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {'logistic regression': LogisticRegression, \n",
    "          'SVM' : SGDClassifier, \n",
    "          'random forest' : RandomForestClassifier, \n",
    "          'xgboost' : xgb.XGBClassifier\n",
    "         }\n",
    "\n",
    "classifier = FBConstructivenessClassifier(X_C3_train, y_C3_train, X_SOCC_a, y_SOCC_a)\n",
    "\n",
    "for model_name, model_class in models.items():\n",
    "    t = time.time()\n",
    "    print(model_name, \":\")\n",
    "    m = model_class()\n",
    "    pipeline = classifier.train_pipeline(classifier = model_class())    \n",
    "    classifier.show_scores(pipeline)\n",
    "    elapsed_time = time.time() - t\n",
    "    print(\"Elapsed time: %.1f s\" % elapsed_time)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_C3_train, y_C3_train], axis = 1)\n",
    "test_df = pd.concat([X_SOCC_a, y_SOCC_a], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dl_experiment(C3_train_df, \n",
    "                      C3_test_df, \n",
    "                      results_csv_path = os.environ['HOME'] + 'models/test_predictions.csv',                       \n",
    "                      model = 'cnn'):\n",
    "\n",
    "\n",
    "    \"\"\"    \n",
    "    \"\"\"    \n",
    "    X_train = C3_train_df['pp_comment_text'].astype(str)\n",
    "    y_train = C3_train_df['constructive_binary']\n",
    "    \n",
    "    X_test = C3_test_df['pp_comment_text'].astype(str)\n",
    "    y_test = C3_test_df['constructive_binary']\n",
    "    \n",
    "    dlclf = DLTextClassifier(X_train, y_train)\n",
    "    \n",
    "    if model.endswith('lstm'):\n",
    "        dlclf.build_bilstm()\n",
    "        \n",
    "    elif model.endswith('cnn'): \n",
    "        dlclf.build_cnn()\n",
    "        \n",
    "    dlclf.train(X_train, y_train)\n",
    "    print('\\nTrain results: \\n\\n')\n",
    "    dlclf.evaluate(X_train, y_train)\n",
    "    \n",
    "    print('\\nTest results: \\n\\n')\n",
    "    dlclf.evaluate(X_test, y_test)\n",
    "    results_df = dlclf.write_model_scores_df(C3_test_df, results_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.rename({'constructive':'constructive_binary'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article_id', 'comment_counter', 'comment_text', 'crowd_toxicity_level',\n",
       "       'SEVERE_TOXICITY_probability', 'SEXUALLY_EXPLICIT_probability',\n",
       "       'TOXICITY_probability', 'TOXICITY_IDENTITY_HATE_probability',\n",
       "       'TOXICITY_INSULT_probability', 'TOXICITY_OBSCENE_probability',\n",
       "       'TOXICITY_THREAT_probability', 'ATTACK_ON_AUTHOR_probability',\n",
       "       'ATTACK_ON_COMMENTER_probability', 'ATTACK_ON_PUBLISHER_probability',\n",
       "       'INCOHERENT_probability', 'INFLAMMATORY_probability',\n",
       "       'LIKELY_TO_REJECT_probability', 'OBSCENE_probability',\n",
       "       'OFF_TOPIC_probability', 'SPAM_probability',\n",
       "       'UNSUBSTANTIAL_probability', 'source',\n",
       "       'njudgements_constructiveness_expt', 'njudgements_toxicity_expt',\n",
       "       'has_conjunctions_and_connectives', 'has_stance_adverbials',\n",
       "       'has_reasoning_verbs', 'has_modals', 'has_shell_nouns', 'length',\n",
       "       'average_word_length', 'ncaps', 'noov', 'readability_score',\n",
       "       'personal_exp_score', 'named_entity_count', 'nSents',\n",
       "       'avg_words_per_sent', 'pos', 'specific_points', 'dialogue', 'no_con',\n",
       "       'evidence', 'personal_story', 'solution', 'no_respect', 'no_non_con',\n",
       "       'provocative', 'sarcastic', 'non_relevant', 'unsubstantial',\n",
       "       'personal_attack', 'teasing', 'no_toxic', 'abusive', 'embarrassment',\n",
       "       'inflammatory', 'pp_comment_text', 'constructive_binary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of encoded docs:  9600\n",
      "Pad sequences (samples x time)\n",
      "Padded data shape: (9600, 100)\n",
      "Number of words not found in glove embeddings:  655\n",
      "Percentage non-zero elements:  0.9757530955461098\n",
      "Building CNN model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 300)          8116500   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 98, 250)           225250    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 49, 250)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 47, 250)           187750    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 23, 250)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 21, 250)           187750    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,780,251\n",
      "Trainable params: 8,780,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training...\n",
      "Train on 8640 samples, validate on 960 samples\n",
      "Epoch 1/5\n",
      "8640/8640 [==============================] - 4s 451us/step - loss: 1.4987 - acc: 0.8385 - val_loss: 0.6408 - val_acc: 0.7583\n",
      "Epoch 2/5\n",
      "8640/8640 [==============================] - 3s 340us/step - loss: 0.4017 - acc: 0.8875 - val_loss: 0.4572 - val_acc: 0.8448\n",
      "Epoch 3/5\n",
      "8640/8640 [==============================] - 3s 341us/step - loss: 0.3675 - acc: 0.8818 - val_loss: 0.4029 - val_acc: 0.8552\n",
      "Epoch 4/5\n",
      "8640/8640 [==============================] - 3s 340us/step - loss: 0.3255 - acc: 0.9013 - val_loss: 0.4365 - val_acc: 0.8333\n",
      "Epoch 5/5\n",
      "8640/8640 [==============================] - 3s 344us/step - loss: 0.2938 - acc: 0.9148 - val_loss: 0.4555 - val_acc: 0.8354\n",
      "\n",
      "Train results: \n",
      "\n",
      "\n",
      "len of encoded docs:  9600\n",
      "Pad sequences (samples x time)\n",
      "Padded data shape: (9600, 100)\n",
      "sklearn micro-F1-Score: 0.8988541666666666\n",
      "\n",
      "Test results: \n",
      "\n",
      "\n",
      "len of encoded docs:  1035\n",
      "Pad sequences (samples x time)\n",
      "Padded data shape: (1035, 100)\n",
      "sklearn micro-F1-Score: 0.7951690821256039\n",
      "len of encoded docs:  1035\n",
      "Pad sequences (samples x time)\n",
      "Padded data shape: (1035, 100)\n",
      "Predictions file written:  /home/vkolhatk/dev/constructiveness/models/test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "run_dl_experiment(train_df, test_df, model = 'cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of encoded docs:  9600\n",
      "Pad sequences (samples x time)\n",
      "Padded data shape: (9600, 100)\n",
      "Number of words not found in glove embeddings:  655\n",
      "Percentage non-zero elements:  0.9757530955461098\n",
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 300)          8116500   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               439296    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 8,556,053\n",
      "Trainable params: 439,553\n",
      "Non-trainable params: 8,116,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training...\n",
      "Train on 8640 samples, validate on 960 samples\n",
      "Epoch 1/5\n",
      "8640/8640 [==============================] - 65s 8ms/step - loss: 0.2410 - acc: 0.8976 - val_loss: 0.2302 - val_acc: 0.9094\n",
      "Epoch 2/5\n",
      "8640/8640 [==============================] - 64s 7ms/step - loss: 0.1872 - acc: 0.9280 - val_loss: 0.1970 - val_acc: 0.9260\n",
      "Epoch 3/5\n",
      "8640/8640 [==============================] - 64s 7ms/step - loss: 0.1773 - acc: 0.9299 - val_loss: 0.1935 - val_acc: 0.9167\n",
      "Epoch 4/5\n",
      "8640/8640 [==============================] - 64s 7ms/step - loss: 0.1692 - acc: 0.9338 - val_loss: 0.1959 - val_acc: 0.9240\n",
      "Epoch 5/5\n",
      "8640/8640 [==============================] - 64s 7ms/step - loss: 0.1664 - acc: 0.9366 - val_loss: 0.1900 - val_acc: 0.9219\n",
      "\n",
      "Train results: \n",
      "\n",
      "\n",
      "len of encoded docs:  9600\n",
      "Pad sequences (samples x time)\n",
      "Padded data shape: (9600, 100)\n",
      "sklearn micro-F1-Score: 0.9477083333333334\n",
      "\n",
      "Test results: \n",
      "\n",
      "\n",
      "len of encoded docs:  1035\n",
      "Pad sequences (samples x time)\n",
      "Padded data shape: (1035, 100)\n",
      "sklearn micro-F1-Score: 0.8782608695652175\n",
      "len of encoded docs:  1035\n",
      "Pad sequences (samples x time)\n",
      "Padded data shape: (1035, 100)\n",
      "Predictions file written:  /home/vkolhatk/dev/constructiveness/models/test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "run_dl_experiment(train_df, test_df, model = 'lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
